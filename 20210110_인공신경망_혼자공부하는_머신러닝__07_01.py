# -*- coding: utf-8 -*-
"""20210110_인공신경망_혼자공부하는 머신러닝._07-01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F5E04ni-NVPLz6p-orPqF2IOaP20IRfo
"""

#1 Keras imported 
import tensorflow as tf
from tensorflow import keras
#2 Fashion MNIST downloaded
(train_input, train_target), (test_input, test_target) =\
keras.datasets.fashion_mnist.load_data()

#3 훈련 데이터 크기 확인
print(train_input.shape, train_target.shape)

"""3-> 60,000 개의 이미지. 이미지의 크기는 28*28
타깃 이미지도 60,000개의 원소가 있는 1차원 배열 
"""

#4 테스트셋 크기 확인 
print(test_input.shape, test_target.shape)

"""10,000개의 이미지; 타깃도 10,000개의 원소."""

#5 훈련데이터 샘플 그림으로 출력하기
import matplotlib.pyplot as plt
fig, axs = plt.subplots(1, 10, figsize=(10,10))
for i in range(10):
  axs[i].imshow(train_input[i], cmap='gray_r')
  axs[i].axis('off')
plt.show()

print([train_target[i] for i in range(10)])

"""8-> 처음 10개 샘플의 타깃값"""

#6 유니크 함수로 레이블 값 확인하기
import numpy as np
print(np.unique(train_target, return_counts=True))

"""9-> *0~9까지 레이블 마다 정확히 6,000개의 샘플이 들어있음."""

#7 Rogistric Regression으로 분류하기
train_scaled= train_input / 255.0 #패션 MNIST의 각 픽셀 0~255 사이의 정수값을 가짐. 255로 나누면 0~1 사이 값으로 정규화됨
print(train_scaled.shape)
train_scaled= train_scaled.reshape(-1, 28*28)
print(train_scaled.shape)

# reshape 함수 피라미터 확인 할것, 4번의 과정은 1차원으로 바꾸는 과정

# 8SGDClassifier; CrossValidation
from sklearn.model_selection import cross_validate
from sklearn.linear_model import SGDClassifier
sc = SGDClassifier(loss='log', max_iter=5, random_state=42)
scores= cross_validate(sc, train_scaled, train_target, n_jobs=-1)
print(np.mean(scores['test_score']))

# 9 max_iter=9
from sklearn.model_selection import cross_validate
from sklearn.linear_model import SGDClassifier
sc = SGDClassifier(loss='log', max_iter=9, random_state=42)
scores= cross_validate(sc, train_scaled, train_target, n_jobs=-1)
print(np.mean(scores['test_score']))

# 10 max_iter=20
from sklearn.model_selection import cross_validate
from sklearn.linear_model import SGDClassifier
sc = SGDClassifier(loss='log', max_iter=9, random_state=42)
scores= cross_validate(sc, train_scaled, train_target, n_jobs=-1)
print(np.mean(scores['test_score']))

"""CrossValidation 은 어느정도 횟차가 지나면 크게 성능향상을 기대할 수 없다.

인공신경망으로 모델제작
"""

#1 Train/Test 분리
from sklearn.model_selection import train_test_split
train_scaled, val_scaled, train_target, val_target = train_test_split(
    train_scaled, train_target, test_size=0.2, random_state=42)

#2 Train_test 분리확인
print(train_scaled.shape, train_target.shape)
print(val_scaled.shape, val_target.shape)

#3 밀집층 만들기
dense = keras.layers.Dense(10, activation='softmax', input_shape=(784,))
#Dense(뉴런개수, 뉴런출력에 적용할 함수, 입력의크기)

#4 만들어진 밀집층으로 신경망 모델 만들기
model = keras.Sequential(dense)

#5모델 수행전 설정단계 A.K.A Compllie 
model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')

"""손실함수의 종류
1. 이진분류 : loss = 'binary_crossentropy'
2. 다중분류 : loss = 'categorical_crossentropy'
-Crossentropy는 타겟 뉴런에 활성화 함수를 적용하고 나머지 뉴런 0으로 만든다. 
-샘플을 정확하게 분류하기 위해서 타겟 뉴런의 출력을 가능한 높여야한다.
- 타겟값을 해당 클래스만 1이고 나머지는 0인 배열로 만드는것을 one-hot encoding이라고 한다.
"""

#6 sparse_categorical_crossentropy를 사용한 이유
print(train_target[:10])
# 타겟값은 모두 정수인데 텐서플로에서 원핫을 하지 않고 가능한 방법이 sparse_categorical_crossentropy이다.

#7 훈련데이터 fit
model.fit(train_scaled, train_target, epochs=5)

"""epoch마다 손실률은 떨어지고 정확도는 올라가고 있다:
 훈련이 잘되고 있다. 
"""

#7 테스트데이터 evaluated
model.evaluate(val_scaled, val_target)